{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOZoyVtdMB0sJdxkPoZqMSY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markobonna/smartsightai/blob/main/AI_Voice_Assistant_Clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q TTS"
      ],
      "metadata": {
        "id": "z-t4M0NaVzxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U numPy==1.21"
      ],
      "metadata": {
        "id": "gKzqsiAWV2zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***restart runtime after installing Numpy***"
      ],
      "metadata": {
        "id": "1aNbPZcTsv4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai-whisper\n",
        "!pip install -q gradio\n",
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "xVAI1DrwV6t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import gradio as gr \n",
        "import openai\n",
        "from TTS.api import TTS"
      ],
      "metadata": {
        "id": "UfzCvGZCV654"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " TTS.list_models()"
      ],
      "metadata": {
        "id": "bYibtDKVV68v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = TTS.list_models()[9]\n",
        "tts = TTS(model_name)"
      ],
      "metadata": {
        "id": "QqSGk6hsV7Cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tts.tts_to_file(text=\"I am ready to hear the world around me\", file_path=\"output.wav\")"
      ],
      "metadata": {
        "id": "mGZ_xhocV7G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio, display\n",
        "\n",
        "display(Audio('output.wav', autoplay=True))"
      ],
      "metadata": {
        "id": "H7TkWJ8eV7MZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"medium\")"
      ],
      "metadata": {
        "id": "8cye09TeV7PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = 'XXXXXXXX'"
      ],
      "metadata": {
        "id": "5aISdTVJV7SF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def voice_chat(user_voice):\n",
        "\n",
        "    messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a kind helpful assistant.\"},\n",
        "    ]\n",
        "          \n",
        "    \n",
        "    user_message = model.transcribe(user_voice)[\"text\"]\n",
        "\n",
        "    #reply = user_message\n",
        "\n",
        "    messages.append(\n",
        "        {\"role\": \"user\", \"content\": user_message},\n",
        "    )\n",
        "\n",
        "    print(messages)\n",
        "\n",
        "    chat = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\", messages=messages\n",
        "    )\n",
        "    \n",
        "    reply = chat.choices[0].message.content\n",
        "    \n",
        "    messages.append({\"role\": \"assistant\", \"content\": reply})\n",
        "\n",
        "    tts.tts_to_file(text=reply, file_path=\"output.wav\")\n",
        "\n",
        "    return(reply, 'output.wav')"
      ],
      "metadata": {
        "id": "Z-r53NfhV7U_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_reply = gr.Textbox(label=\"ChatGPT Text\")\n",
        "voice_reply = gr.Audio('output.wav')\n",
        "\n",
        "gr.Interface(\n",
        "    title = 'AI Voice Assistant with ChatGPT AI', \n",
        "    fn=voice_chat, \n",
        "    inputs=[\n",
        "        gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n",
        "    ],\n",
        "\n",
        "    outputs=[\n",
        "        text_reply,  voice_reply\n",
        "    ], live = True).launch(share=True)"
      ],
      "metadata": {
        "id": "JQ0WS9_LV7X5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
